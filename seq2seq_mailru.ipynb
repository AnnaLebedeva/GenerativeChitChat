{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В этом проекте я обучаю модель, которая будет принимать на вход текст вопроса и выдавать ответ. Модель на основе RNN(GRU) и с применением Attention."
      ],
      "metadata": {
        "id": "hZ60STxnn-r4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pRVcBmYx9D81"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import json\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные - это датасет mail.ru: https://www.kaggle.com/c/chit-chat-encoders/data. Данные находятся в формате tsv, где табуляцией отделен вопрос от ответа. Я предварительно обрезала датасет до 500 тысяч примеров."
      ],
      "metadata": {
        "id": "nH49c_3MhQa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_name = \"mail_ru\"\n",
        "corpus = ''\n",
        "datafile = 'train_cut_100000.txt'"
      ],
      "metadata": {
        "id": "5fV0MAK0Vl8K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша следующая задача — создать словарь и загрузить в память пары предложений «запрос/ответ».\n",
        "\n",
        "Для операций с предложениями мы должны представить их в виде эмбедингов. Для этого мы определяем класс Voc, который хранит отображение слов в индексы, обратное отображение индексов в слова, количество каждого слова и общее количество слов. Класс содержит методы для добавления слова в словарь (addWord), добавления всех слов в предложение (addSentence) и для обрезки редко встречающихся слов (trim)."
      ],
      "metadata": {
        "id": "fhgob1SahMhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_token = 0  # пад-токен\n",
        "SOS_token = 1  # токен начала предложения\n",
        "EOS_token = 2  # токен конца предложения\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # метод удаляет редко встречающиеся слова из словаря\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # заново инициализируем словари\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "metadata": {
        "id": "Z36LqKwRKhym"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 25  # максимальная длина предложения (до куда паддить)\n",
        "\n",
        "# переводим строку в Unicode в ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# привозим к нижнему регистру, обрезаем редкие слова, убираем не буквенные символы\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^а-яА-Я.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# помещаем предобработанные пары вопрос/ответ в список и возвращаем объект voc\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines = open(datafile, encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs\n",
        "\n",
        "# функция возвращает True если оба предложения в паре короче порога MAX_LENGTH\n",
        "def filterPair(p):\n",
        "    # для вопросов необходимо зарезервировать последнее место для токена EOS\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "# фильтруем пары согласно функции выше\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "# функция возвращает заполненный объект voc object и список пар\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Start preparing training data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Counted words:\", voc.num_words)\n",
        "    return voc, pairs\n",
        "\n",
        "# загружаем объект voc и пары\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "# печать пар, чтобы понять, как они выглядят после обработки\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m9BhADlKvgm",
        "outputId": "5ee77626-f968-4401-fb0a-8e31498a8363"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data ...\n",
            "Reading lines...\n",
            "Read 100001 sentence pairs\n",
            "Trimmed to 100000 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 109692\n",
            "\n",
            "pairs:\n",
            "['он трогает меня там и я не могу сказать нет почему так ?', 'хочется тебе этого . поэтому и молчишь . молчание знак согласия .']\n",
            "['а приличная поза .это какая ?', 'все приличные . лишь бы поглубже забратся !']\n",
            "['с какои фразы начинается ваше доброе утро . доброго утра .', 'в даныи момент рота подъем .']\n",
            "['нужен ли автомобиль семье с маленьким ребенком ?', 'еще как нужен !']\n",
            "['как вам мое фото ?', 'наверное подслушивать очень любишь .']\n",
            "['ты в кого тут влюбилась ся признаваися ?', 'а не скажу .']\n",
            "['что вас больше всего раздрожает в людях ?', 'зависть лицемерие грубость и чрезмерная раздражительность']\n",
            "['почему девушки не любят добрых парнеи ?', 'а может они просто не замечают этого качества !']\n",
            "['мужчина ! . что тебя может глубоко тронуть в женщине ?', 'ои да не пугаи ты их так']\n",
            "['а ты знаешь зачем тебе даны чувства ?', 'чтобы точно знать что я человек . а не робот']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нам нужно преобразовать слова в наших парах предложений в соответствующие индексы из словаря и передать это моделям. Мы будем производить обучение мини-батчами. Чтобы разместить предложения разного размера в одном и том же батче, мы создадим наш входной тензор размером (max_length, batch_size), где предложения короче max_length дополняются нулями после EOS_token.\n",
        "Если мы просто преобразуем наши предложения в тензоры, преобразовывая слова в их индексы (indexesFromSentence) и пады, наш тензор будет иметь размер (batch_size, max_length), и индексация по первому измерению вернет полную последовательность во всех таймстемпах. Однако нам нужно иметь возможность индексировать наш батч во времени и по всем последовательностям в батче. Поэтому мы транспонируем форму входного пакета в (max_length, batch_size), чтобы индексирование по первому измерению возвращало таймстемп для всех предложений в пакете. Мы обрабатываем это транспонирование неявно в функции zeroPadding."
      ],
      "metadata": {
        "id": "E6aewBDun7Ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция inputVar обрабатывает процесс преобразования предложений в тензор, в конечном итоге создавая тензор правильной формы, дополненный нулями. Она также возвращает тензор длин для каждой из последовательностей в пакете, который позже будет передан нашему декодеру.\n",
        "\n",
        "Функция outputVar выполняет ту же функцию, что и inputVar, но вместо возврата тензора длин она возвращает тензор бинарной маски и максимальную целевую длину предложения. Тензор бинарной маски имеет ту же форму, что и выходной целевой тензор, но каждый элемент, являющийся PAD_token, равен 0, а все остальные — 1.\n",
        "\n",
        "batch2TrainData просто берет набор пар и возвращает входные и целевые тензоры, используя вышеупомянутые функции."
      ],
      "metadata": {
        "id": "cHfGafQ0qD95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# возращает входную последовательность с падами и длины предложений\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# возращает целевую последовательность с падами, padding mask и максимальную длину целевого предложения\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# возвращает все эти величины для всех предложений в батче\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "\n",
        "# вывод примера\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCzI__viSoZB",
        "outputId": "8432f147-fa3d-46e5-844f-ef8733a60555"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variable: tensor([[  230,    73,    13,   394,    73],\n",
            "        [  267,   185,   126,  1113,   913],\n",
            "        [  147,  4484,  2375,  1417,  3702],\n",
            "        [ 2286,   106, 20710, 14050,  7183],\n",
            "        [    9,  2311,  1288,   500,    15],\n",
            "        [23721,     7,  6839,  5095,     2],\n",
            "        [ 2528,  3392,    15,    15,     0],\n",
            "        [  367,    15,     2,     2,     0],\n",
            "        [   89,     2,     0,     0,     0],\n",
            "        [23721,     0,     0,     0,     0],\n",
            "        [ 2096,     0,     0,     0,     0],\n",
            "        [   15,     0,     0,     0,     0],\n",
            "        [    2,     0,     0,     0,     0]])\n",
            "lengths: tensor([13,  9,  8,  8,  6])\n",
            "target_variable: tensor([[ 2316, 66552,  1235,  8105,     9],\n",
            "        [    9, 15734, 48674,    64,    73],\n",
            "        [10607,    19,   278,  1518,    25],\n",
            "        [   19,   131,     9,     2,   111],\n",
            "        [   20, 66553,  3719,     0,  5016],\n",
            "        [  276,    57,  1694,     0,  3150],\n",
            "        [ 6441,    19,    19,     0,     2],\n",
            "        [    2,     2,     2,     0,     0]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True, False,  True],\n",
            "        [ True,  True,  True, False,  True],\n",
            "        [ True,  True,  True, False,  True],\n",
            "        [ True,  True,  True, False, False]])\n",
            "max_target_len: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве модели используется RNN, а именно, bidirectional GRU."
      ],
      "metadata": {
        "id": "Ydyzl2d8q-Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # преобразуем индексы слов в эмбединги\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # формируем батч последовательностей с падами для модуля RNN\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "kiEr7FLpOITw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем слой Attention согласно тому, как он описан в этой статье: https://arxiv.org/abs/1508.04025\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "wzwBvTewOIV5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем декодер."
      ],
      "metadata": {
        "id": "L0vRjQJkszCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # определяем слои\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "kiSfNPH9OIXz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поскольку мы имеем дело с батчами последовательностей, дополненных падами, мы не можем просто учитывать все элементы тензора при вычислении лосса. Мы определяем maskNLLLoss для расчета наших потерь на основе выходного тензора нашего декодера, целевого тензора и бинарного тензора маски, описывающего заполнение целевого тензора. Эта функция потерь вычисляет среднее отрицательное логарифмическое правдоподобие элементов, которые соответствуют 1 в маске тензора."
      ],
      "metadata": {
        "id": "uJrc4oFQtP_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "metadata": {
        "id": "ldf1P6fwOIaM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция обучения содержит алгоритм для одной итерации обучения (один батч входных данных).\n",
        "\n",
        "Здесь используется teacher forcing. Это означает, что с некоторой вероятностью, заданной с помощью параметра Teacher_forcing_ratio, мы используем текущее целевое слово в качестве следующего ввода декодера, а не используем текущее предположение декодера. Этот метод помогает более эффективному обучению. Однако teacher forcing может привести к нестабильности модели во время вывода, поскольку у декодера может не быть достаточного шанса действительно создать свои собственные выходные последовательности во время обучения.\n",
        "Второй прием — gradient clipping. Это широко используемый метод для борьбы с проблемой «взрывающегося градиента». По сути, обрезав или установив пороговое значение градиентов до максимального значения, мы предотвращаем экспоненциальный рост градиентов и либо слишком быстрый рост, либо слишком быстрое падение функции."
      ],
      "metadata": {
        "id": "UlVeiP1Ytn0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 20\n",
        "\n",
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "metadata": {
        "id": "vwMZZE20OlNc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем модель на наших данных. Функция trainIters отвечает за запуск n_iterations обучения с учетом переданных моделей, оптимизаторов, данных и т. д."
      ],
      "metadata": {
        "id": "9uHGeYxTun4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # загружаем батчи для каждой итерации\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # инициализируем\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # цикл обучения\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "        print_loss += loss\n",
        "\n",
        " \n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "\n",
        "\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
      ],
      "metadata": {
        "id": "P5mt5BPcOlPz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь нам необходимо установить, в каком виде отображать выходную последовательность. За это отвечает декодер. Жадное декодирование — это метод декодирования, который мы используем во время обучения, когда мы не используем teacher forcing. Другими словами, для каждого временного шага мы просто выбираем слово из decoder_output с самым высоким значением softmax. Этот метод декодирования оптимален на уровне одного временного шага.\n",
        "\n",
        "Чтобы облегчить операцию жадного декодирования, мы определяем класс GreedySearchDecoder. При запуске объект этого класса принимает входную последовательность (input_seq) размера (input_seq length, 1), тензор входной длины (input_length) и max_length для ограничения длины предложения ответа."
      ],
      "metadata": {
        "id": "OpbO2v_TwO4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "\n",
        "        return all_tokens, all_scores"
      ],
      "metadata": {
        "id": "DEmxjiMFOlSG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже функция для визуальной оценки получившегося ответа.В этой функции мы получаем ответ с помощью модели, конвертируем индексы ответа в слова и возвращаем список декодированных слов.\n",
        "\n",
        "AssessmentInput действует как пользовательский интерфейс для нашего чат-бота. При вызове появится текстовое поле ввода, в котором мы можем ввести наше предложение запроса. После ввода нашего входного предложения и нажатия Enter наш текст нормализуется так же, как и наши обучающие данные, и в конечном итоге передается в функцию оценки для получения декодированного выходного предложения. Мы зацикливаем этот процесс, поэтому мы можем продолжать общаться с нашим ботом, пока не введем либо «q», либо «quit».\n",
        "\n",
        "Если вводится предложение, содержащее слово, которого нет в словаре, мы от лица модели просим пользователя перефразировать."
      ],
      "metadata": {
        "id": "XlEfcrdVw5UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "\n",
        "\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "\n",
        "            input_sentence = input('> ')\n",
        "\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Я тебя не понимаю, перефразируй, пожалуйста.\")"
      ],
      "metadata": {
        "id": "mTdMS2-AOlUq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для запуска нам необходимо инициализировать отдельные модели энкодера и декодера. Мы устанавливаем желаемые конфигурации, выбираем запуск с нуля или устанавливаем контрольную точку для загрузки, а также строим и инициализируем модели."
      ],
      "metadata": {
        "id": "H_q-ME_Xxx3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "loadFilename = None\n",
        "checkpoint_iter = 4000\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if loadFilename:\n",
        "\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sByvlOL_Xb97",
        "outputId": "bc5b1843-0b4d-42ff-ecb5-e78fde5a74ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем обучение. Сначала мы устанавливаем параметры обучения, затем инициализируем наши оптимизаторы и, наконец, вызываем функцию trainIters для запуска итераций обучения.\n",
        "Я пробовала обучить модель сначала на 100 тысячах примеров, и получились неплохие результаты. Потом я взяла миллион примеров, и у меня не хватило памяти в колабе. Потом я взяла 500 тысяч примеров, но уменьшила число итераций, чтобы модель обучалась не дольше получаса. В итоге результаты были не очень хорошие, модель явно недообучилась. Поэтому я вернулась к 100 тысячам примеров, но вернула количество итераций равно 4000."
      ],
      "metadata": {
        "id": "nGeAYGYTyVzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 4000\n",
        "print_every = 100\n",
        "save_every = 500\n",
        "\n",
        "\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy6PwfeFOlaV",
        "outputId": "5c26f362-e2a7-4473-c530-8ba4a1c7c469"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 100; Percent complete: 2.5%; Average loss: 7.8113\n",
            "Iteration: 200; Percent complete: 5.0%; Average loss: 7.0917\n",
            "Iteration: 300; Percent complete: 7.5%; Average loss: 6.9708\n",
            "Iteration: 400; Percent complete: 10.0%; Average loss: 6.8943\n",
            "Iteration: 500; Percent complete: 12.5%; Average loss: 6.8082\n",
            "Iteration: 600; Percent complete: 15.0%; Average loss: 6.7702\n",
            "Iteration: 700; Percent complete: 17.5%; Average loss: 6.7291\n",
            "Iteration: 800; Percent complete: 20.0%; Average loss: 6.6326\n",
            "Iteration: 900; Percent complete: 22.5%; Average loss: 6.6284\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 6.5809\n",
            "Iteration: 1100; Percent complete: 27.5%; Average loss: 6.5549\n",
            "Iteration: 1200; Percent complete: 30.0%; Average loss: 6.5310\n",
            "Iteration: 1300; Percent complete: 32.5%; Average loss: 6.4655\n",
            "Iteration: 1400; Percent complete: 35.0%; Average loss: 6.4314\n",
            "Iteration: 1500; Percent complete: 37.5%; Average loss: 6.4365\n",
            "Iteration: 1600; Percent complete: 40.0%; Average loss: 6.3621\n",
            "Iteration: 1700; Percent complete: 42.5%; Average loss: 6.3503\n",
            "Iteration: 1800; Percent complete: 45.0%; Average loss: 6.2866\n",
            "Iteration: 1900; Percent complete: 47.5%; Average loss: 6.2697\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 6.2202\n",
            "Iteration: 2100; Percent complete: 52.5%; Average loss: 6.1840\n",
            "Iteration: 2200; Percent complete: 55.0%; Average loss: 6.1580\n",
            "Iteration: 2300; Percent complete: 57.5%; Average loss: 6.0833\n",
            "Iteration: 2400; Percent complete: 60.0%; Average loss: 6.0990\n",
            "Iteration: 2500; Percent complete: 62.5%; Average loss: 6.0215\n",
            "Iteration: 2600; Percent complete: 65.0%; Average loss: 6.0437\n",
            "Iteration: 2700; Percent complete: 67.5%; Average loss: 5.9791\n",
            "Iteration: 2800; Percent complete: 70.0%; Average loss: 5.9966\n",
            "Iteration: 2900; Percent complete: 72.5%; Average loss: 5.9542\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 5.8787\n",
            "Iteration: 3100; Percent complete: 77.5%; Average loss: 5.8670\n",
            "Iteration: 3200; Percent complete: 80.0%; Average loss: 5.8220\n",
            "Iteration: 3300; Percent complete: 82.5%; Average loss: 5.8069\n",
            "Iteration: 3400; Percent complete: 85.0%; Average loss: 5.7284\n",
            "Iteration: 3500; Percent complete: 87.5%; Average loss: 5.7171\n",
            "Iteration: 3600; Percent complete: 90.0%; Average loss: 5.6592\n",
            "Iteration: 3700; Percent complete: 92.5%; Average loss: 5.6727\n",
            "Iteration: 3800; Percent complete: 95.0%; Average loss: 5.6258\n",
            "Iteration: 3900; Percent complete: 97.5%; Average loss: 5.6282\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.5541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Производим визуальную оценку ответов модели."
      ],
      "metadata": {
        "id": "I4FCBP_Zy0ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Begin chatting (uncomment and run the following line to begin)\n",
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5iZspbMuOlcn",
        "outputId": "8e767b69-ae59-40b8-bc9f-2ee8d3b35859"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> как дела, моделька\n",
            "Я тебя не понимаю, перефразируй, пожалуйста.\n",
            "> как дела, мисс модель\n",
            "Bot: никак . и не знаю . . . .\n",
            "> ну вот. опять многоточия\n",
            "Bot: я бы не знаю . . . . .\n",
            "> такого же не было!\n",
            "Bot: да и не сможешь ! ! ! ! ! ! ! !\n",
            "> да я-то точно не смогу.\n",
            "Bot: ты не обманешь ? . . . . . . . .\n",
            "> нет. давай к вопросам.\n",
            "Bot: не знаю . . как бы не знаю . . . . . .\n",
            "> ты капризная. почему плохо работаешь?\n",
            "Bot: я не знаю что я не знаю . . . .\n",
            "> всё ты знаешь. почему трава зеленая?\n",
            "Bot: я думаю что я не знаю . . я не знаю . . как то . .\n",
            "> кто убил кеннеди?\n",
            "Я тебя не понимаю, перефразируй, пожалуйста.\n",
            "> кто президент америки?\n",
            "Bot: я бы не знаю . . . . .\n",
            "> почему солнце светит?\n",
            "Bot: потому что у них не тянет . и тп\n",
            "> почему люди стареют?\n",
            "Bot: потому что они не бесчувственные\n",
            "> как познакомились мистер и миссис смит?\n",
            "Bot: не знаю что ли ? и наслождаися\n",
            "> где живет катя?\n",
            "Bot: в россии . . . . . .\n",
            "> где находится санкт-петербург?\n",
            "Bot: в россии . . . . . .\n",
            "> где находится нью-йорк?\n",
            "Bot: в палате . . . . . . . . .\n",
            "> как найти клона?\n",
            "Bot: а зачем ? ? . . .\n",
            "> мудро. мудро.\n",
            "Bot: я не знаю . . . . . .\n",
            "> расскажи интересную историю\n",
            "Bot: искатели . . и иди\n",
            "> как научиться рисовать?\n",
            "Bot: не знаю . как то и не знаю . . . . .\n",
            "> мне кажется, тебя надо обучить на предложениях без \"не знаю\"\n",
            "Bot: да и не знаю . и не знаю . . . .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3de5b829fbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Begin chatting (uncomment and run the following line to begin)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-42a3c985f6e4>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Get input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Check if it is quit case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pC2S8oXcMlPb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}